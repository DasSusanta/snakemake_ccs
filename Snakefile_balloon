import os
import json

# read the IDs for input SMILES
with open('data/input.smi', 'r') as f:
    lines = f.readlines()
lines = [x for x in lines if len(x.strip()) > 0]
ids = [x.split()[0] for x in lines]

with open('paths.json', 'r') as f:
    paths = json.load(f)

with open('arguments.json', 'r') as f:
    args = json.load(f)

# record number of charge models
model_num = {}
for theID in ids:
    model_num[theID] = {}
    for thecharge in os.listdir('results/' + theID):
        if int(thecharge) not in args['consider_adducts_of_charges']:
            print('skipped charge of', thecharge, 'because not in ', args['consider_adducts_of_charges'])
            continue
        with open('results/' + theID + '/' + thecharge + '/charged_model.smi', 'r') as f:
            lines = f.readlines()
        model_num[theID][thecharge] = len(lines)

# record the smiles
smiles = {}
for theID in ids:
    smiles[theID] = {}
    for thecharge in model_num[theID]:
        smiles[theID][thecharge] = {}
        with open('results/' + theID + '/' + thecharge + '/charged_model.smi', 'r') as f:
            lines = f.readlines()
        for i in range(len(lines)):
            smiles[theID][thecharge][str(i)] = lines[i].strip()

# get list of target files
targets = []
for theID in model_num:
    for thecharge in  model_num[theID]:
        for modelID in range(model_num[theID][thecharge]):
            targets.append('results/{}/{}/generated_conformers/model{}.tar.gz'.format(theID, thecharge, modelID))
print(targets)
rule all:
    input: targets

rule generate_sdf:
    input: 'results/{label}/{charge}/charged_model.smi'
    output: temp('results/{label}/{charge}/generated_conformers/model{model}.sdf')
    params: smiles = lambda wildcards: smiles[wildcards.label][wildcards.charge][wildcards.model]
    shell: 
        '''
        echo "{params.smiles}"
        balloon --nconfs 1 --noGA "{params.smiles}" {output}
        '''

rule generate_confs:
    input: 'results/{label}/{charge}/generated_conformers/model{model}.sdf'
    output: ('results/{label}/{charge}/generated_conformers/collect_model{model}.xyz')
    params: mmffpath = paths['mmff']
    shell: 
        '''
        balloon -f {params.mmffpath} --nconfs 1000 --nGenerations 300 --rebuildGeometry {input} {output}
        '''

rule separate_files:
    input: 'results/{label}/{charge}/generated_conformers/collect_model{model}.xyz'
    output: 'results/{label}/{charge}/generated_conformers/model{model}/0.xyz'
    run:
        import os
        from ase.io import read
        
        dirpath = '/'.join(str(output).split('/')[:-1])
        if not os.path.isdir(dirpath):
            os.mkdir(dirpath)
        
        geom = read(str(input), index=':')
        for i in range(len(geom)):
            geom[i].write(dirpath + '/{}.xyz'.format(i))

rule compress:
     input: lambda wildcards: expand("results/{label}/{adduct}/generated_conformers/model{model}/0.xyz", label=wildcards.label, adduct=wildcards.adduct, model=range(model_num[wildcards.label][wildcards.adduct]))
     output: "results/{label}/{adduct}/generated_conformers/model0.tar.gz"
     shell:
            """
            cd results/{wildcards.label}/{wildcards.adduct}/generated_conformers/
            for d in *; do
                if [[ -d $d ]]; then
                    tar -zcvf "$d".tar.gz $d
                fi
            done
            """

